{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Getting Started: Your First ML Model\n",
    "\n",
    "Welcome to your first hands-on machine learning experience! In this notebook, we'll build a simple but complete ML pipeline.\n",
    "\n",
    "**Learning Goals:**\n",
    "- Load and explore real data\n",
    "- Build your first ML model\n",
    "- Make predictions\n",
    "- Visualize results\n",
    "\n",
    "**Sources:**\n",
    "- Dataset: Iris dataset from scikit-learn\n",
    "- Method: Based on \"Introduction to Statistical Learning\" Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"🎉 Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Step 1: Load and Explore Data\n",
    "\n",
    "We'll use the famous Iris dataset - perfect for beginners!\n",
    "\n",
    "**About the Iris Dataset:**\n",
    "- 150 samples of iris flowers\n",
    "- 4 features: sepal length, sepal width, petal length, petal width\n",
    "- 3 species: setosa, versicolor, virginica\n",
    "- Source: R.A. Fisher (1936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features (measurements)\n",
    "y = iris.target  # Labels (species)\n",
    "\n",
    "# Create a DataFrame for easier exploration\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['species'] = iris.target_names[y]\n",
    "\n",
    "print(\"📐 Dataset shape:\", df.shape)\n",
    "print(\"\\n🔍 First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n🌺 Species distribution:\")\n",
    "print(df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize our data!\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('🌸 Iris Dataset: Feature Distributions by Species', fontsize=16)\n",
    "\n",
    "features = iris.feature_names\n",
    "for i, feature in enumerate(features):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    for species in iris.target_names:\n",
    "        data = df[df['species'] == species][feature]\n",
    "        axes[row, col].hist(data, alpha=0.7, label=species, bins=10)\n",
    "    \n",
    "    axes[row, col].set_title(feature.replace('_', ' ').title())\n",
    "    axes[row, col].set_xlabel('Measurement (cm)')\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].legend()\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 Notice how different species have different measurement patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Step 2: Build Your First ML Model\n",
    "\n",
    "We'll use **Logistic Regression** - a simple but powerful algorithm!\n",
    "\n",
    "**Why Logistic Regression?**\n",
    "- Easy to understand and interpret\n",
    "- Works well for classification problems\n",
    "- Good baseline model\n",
    "\n",
    "**Source:** \"Pattern Recognition and Machine Learning\" - Bishop, Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a: Split data into training and testing sets\n",
    "# This follows the ML best practice of train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"📚 Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"🧪 Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"📊 Split ratio: {X_train.shape[0]/(X_train.shape[0] + X_test.shape[0]):.1%} train, {X_test.shape[0]/(X_train.shape[0] + X_test.shape[0]):.1%} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b: Create and train the model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model (this is where the \"learning\" happens!)\n",
    "print(\"🎓 Training the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"✅ Model training complete!\")\n",
    "\n",
    "# The model has now \"learned\" patterns from the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔮 Step 3: Make Predictions\n",
    "\n",
    "Now let's see how well our model performs on new, unseen data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"🎯 Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Detailed performance report\n",
    "print(\"\\n📊 Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some individual predictions!\n",
    "print(\"🔮 Individual Predictions:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show first 10 test samples\n",
    "for i in range(10):\n",
    "    sample = X_test[i:i+1]  # Get single sample\n",
    "    prediction = model.predict(sample)[0]\n",
    "    actual = y_test[i]\n",
    "    \n",
    "    pred_name = iris.target_names[prediction]\n",
    "    actual_name = iris.target_names[actual]\n",
    "    \n",
    "    status = \"✅\" if prediction == actual else \"❌\"\n",
    "    \n",
    "    print(f\"Sample {i+1}: {status}\")\n",
    "    print(f\"  Measurements: {sample[0]}\")\n",
    "    print(f\"  Predicted: {pred_name}\")\n",
    "    print(f\"  Actual: {actual_name}\")\n",
    "    print()\n",
    "\n",
    "# Get prediction probabilities (confidence)\n",
    "probabilities = model.predict_proba(X_test[:5])\n",
    "print(\"🎲 Prediction Probabilities (first 5 samples):\")\n",
    "for i, probs in enumerate(probabilities):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for j, prob in enumerate(probs):\n",
    "        print(f\"  {iris.target_names[j]}: {prob:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Step 4: Visualize Results\n",
    "\n",
    "Let's create some beautiful visualizations to understand our model better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=iris.target_names, \n",
    "            yticklabels=iris.target_names)\n",
    "plt.title('🎯 Confusion Matrix: How Well Did We Do?')\n",
    "plt.xlabel('Predicted Species')\n",
    "plt.ylabel('Actual Species')\n",
    "plt.show()\n",
    "\n",
    "print(\"💡 Perfect predictions appear on the diagonal!\")\n",
    "print(\"❌ Mistakes appear off the diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Visualization\n",
    "feature_importance = np.abs(model.coef_[0])  # Get absolute coefficients\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(iris.feature_names, feature_importance, \n",
    "               color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
    "plt.title('🔍 Feature Importance: Which Measurements Matter Most?')\n",
    "plt.xlabel('Flower Measurements')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, importance in zip(bars, feature_importance):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{importance:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "most_important = iris.feature_names[np.argmax(feature_importance)]\n",
    "print(f\"🏆 Most important feature: {most_important}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎮 Interactive Playground: Make Your Own Predictions!\n",
    "\n",
    "Now it's your turn! Try different flower measurements and see what our model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_iris_species(sepal_length, sepal_width, petal_length, petal_width):\n",
    "    \"\"\"\n",
    "    Predict iris species based on measurements\n",
    "    \n",
    "    Parameters:\n",
    "    - sepal_length: length of sepal in cm (typical range: 4.3-7.9)\n",
    "    - sepal_width: width of sepal in cm (typical range: 2.0-4.4)\n",
    "    - petal_length: length of petal in cm (typical range: 1.0-6.9)\n",
    "    - petal_width: width of petal in cm (typical range: 0.1-2.5)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create input array\n",
    "    measurements = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(measurements)[0]\n",
    "    probabilities = model.predict_proba(measurements)[0]\n",
    "    \n",
    "    # Get species name\n",
    "    predicted_species = iris.target_names[prediction]\n",
    "    \n",
    "    print(f\"🌸 Flower Measurements:\")\n",
    "    print(f\"  Sepal: {sepal_length} cm × {sepal_width} cm\")\n",
    "    print(f\"  Petal: {petal_length} cm × {petal_width} cm\")\n",
    "    print(f\"\\n🔮 Prediction: {predicted_species.upper()}\")\n",
    "    print(f\"\\n🎲 Confidence Scores:\")\n",
    "    for species, prob in zip(iris.target_names, probabilities):\n",
    "        print(f\"  {species}: {prob:.1%}\")\n",
    "    \n",
    "    return predicted_species\n",
    "\n",
    "# Try some examples!\n",
    "print(\"🧪 Example 1: Small flower\")\n",
    "predict_iris_species(4.5, 2.3, 1.3, 0.3)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"🧪 Example 2: Large flower\")\n",
    "predict_iris_species(7.2, 3.6, 6.1, 2.5)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"🧪 Example 3: Medium flower\")\n",
    "predict_iris_species(5.8, 2.7, 4.1, 1.3)\n",
    "\n",
    "print(\"\\n💡 Try your own measurements by calling:\")\n",
    "print(\"predict_iris_species(sepal_length, sepal_width, petal_length, petal_width)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 What You've Learned\n",
    "\n",
    "Congratulations! You've just completed your first end-to-end machine learning project. Here's what you accomplished:\n",
    "\n",
    "### ✅ Skills Acquired:\n",
    "1. **Data Loading & Exploration** - Understanding your dataset\n",
    "2. **Data Visualization** - Creating meaningful plots\n",
    "3. **Model Training** - Teaching an algorithm to recognize patterns\n",
    "4. **Model Evaluation** - Measuring how well it performs\n",
    "5. **Making Predictions** - Using the model on new data\n",
    "\n",
    "### 🧠 Key Concepts:\n",
    "- **Supervised Learning**: Learning from labeled examples\n",
    "- **Train-Test Split**: Separating data for training and evaluation\n",
    "- **Classification**: Predicting categories (species)\n",
    "- **Model Accuracy**: How often the model is correct\n",
    "- **Feature Importance**: Which measurements matter most\n",
    "\n",
    "### 📚 Sources Referenced:\n",
    "- Dataset: Fisher, R.A. \"The use of multiple measurements in taxonomic problems\" (1936)\n",
    "- Methodology: \"Introduction to Statistical Learning\" - James et al.\n",
    "- Logistic Regression: \"Pattern Recognition and Machine Learning\" - Bishop\n",
    "\n",
    "## 🚀 Next Steps\n",
    "\n",
    "Ready for more? Here are your next learning adventures:\n",
    "\n",
    "1. **[Mathematics for ML](../02_Mathematics/)** - Dive deeper into the math behind ML\n",
    "2. **[Data Processing](../05_Data_Processing/)** - Learn advanced data handling techniques\n",
    "3. **[Classical ML Algorithms](../06_Classical_ML/)** - Explore more powerful algorithms\n",
    "\n",
    "### 💪 Challenge Yourself:\n",
    "Try modifying this notebook:\n",
    "- Use only 2 features instead of 4\n",
    "- Try a different algorithm (Decision Tree, Random Forest)\n",
    "- Create your own visualizations\n",
    "- Experiment with different train-test split ratios\n",
    "\n",
    "**Remember**: The best way to learn ML is by doing. Keep experimenting! 🔬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}